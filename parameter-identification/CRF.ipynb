{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence labelling in NLP\n",
    "\n",
    "* goal\n",
    "    * assign a label to each member in the sequence.\n",
    "* usage\n",
    "    * extract words or phrases of particular types from a given sentence or paragraph.  \n",
    "\n",
    "# Conditional Random Field (CRF) \n",
    "\n",
    "* type of __probabilistic graphical model__ that can be used to model sequential data, such as labels of words in a sentence.\n",
    "* useful when..\n",
    "    * take advantage of the __surrounding context__ when labelling tokens in a sequence\n",
    "* first proposal\n",
    "    * Lafferty et al.(http://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&context=cis_papers)\n",
    "* steps\n",
    "    1. design a set of __feature functions__ to extract features for each word in a sentence.\n",
    "    2. During model training, CRF will determine the weights of different feature functions that will __maximize the likelihood__ of the labels in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path  \n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk import RegexpParser\n",
    "import re\n",
    "\n",
    "raw_data = json.loads(Path('merged_set.json').read_text(), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for data in raw_data:\n",
    "    temp_list = [(t[0], t[1]) for t in data]\n",
    "    docs.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Given', 'X'),\n",
       " ('an', 'X'),\n",
       " ('array', 'B-param'),\n",
       " ('of', 'I-param'),\n",
       " ('scores,', 'I-param'),\n",
       " ('return', 'X'),\n",
       " ('true', 'X'),\n",
       " ('if', 'X'),\n",
       " ('each', 'X'),\n",
       " ('score', 'X'),\n",
       " ('is', 'X'),\n",
       " ('equal', 'X'),\n",
       " ('or', 'X'),\n",
       " ('greater', 'X'),\n",
       " ('than', 'X'),\n",
       " ('the', 'X'),\n",
       " ('one', 'X'),\n",
       " ('before.', 'X'),\n",
       " ('The', 'X'),\n",
       " ('array', 'B-param'),\n",
       " ('will', 'X'),\n",
       " ('be', 'X'),\n",
       " ('length', 'X'),\n",
       " ('2', 'X'),\n",
       " ('or', 'X'),\n",
       " ('more.', 'X')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Generating Part-of-Speech Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "data = []\n",
    "for i, doc in enumerate(docs):\n",
    "\n",
    "    tokens = [token for token, label in doc]\n",
    "\n",
    "    # POS tagging\n",
    "    pos_tagged = nltk.pos_tag(tokens)\n",
    "\n",
    "    # Take the word, POS tag, and its label\n",
    "    data.append([(word, pos, label) for (word, label), (word, pos) in zip(doc, pos_tagged)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Given', 'VBN', 'X'),\n",
       " ('an', 'DT', 'X'),\n",
       " ('array', 'NN', 'B-param'),\n",
       " ('of', 'IN', 'I-param'),\n",
       " ('scores,', 'JJ', 'I-param'),\n",
       " ('return', 'NN', 'X'),\n",
       " ('true', 'JJ', 'X'),\n",
       " ('if', 'IN', 'X'),\n",
       " ('each', 'DT', 'X'),\n",
       " ('score', 'NN', 'X'),\n",
       " ('is', 'VBZ', 'X'),\n",
       " ('equal', 'JJ', 'X'),\n",
       " ('or', 'CC', 'X'),\n",
       " ('greater', 'JJR', 'X'),\n",
       " ('than', 'IN', 'X'),\n",
       " ('the', 'DT', 'X'),\n",
       " ('one', 'CD', 'X'),\n",
       " ('before.', 'NN', 'X'),\n",
       " ('The', 'DT', 'X'),\n",
       " ('array', 'NN', 'B-param'),\n",
       " ('will', 'MD', 'X'),\n",
       " ('be', 'VB', 'X'),\n",
       " ('length', 'JJ', 'X'),\n",
       " ('2', 'CD', 'X'),\n",
       " ('or', 'CC', 'X'),\n",
       " ('more.', 'VB', 'X')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Generating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(doc, i):\n",
    "    word = doc[i][0]\n",
    "    postag = doc[i][1]\n",
    "\n",
    "    # Common features (for every words)\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag\n",
    "    ]\n",
    "    # features for words which is not the beginning of a decument\n",
    "    if i > 0:\n",
    "        word1 = doc[i-1][0]\n",
    "        postag1 = doc[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:word.isdigit=%s' % word1.isdigit(),\n",
    "            '-1:postag=' + postag1\n",
    "        ])\n",
    "    # feature for a word which is the beginning of a document\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    # eatures for words which is not the end of a decument\n",
    "    if i < len(doc)-1: \n",
    "        word1 = doc[i+1][0]\n",
    "        postag1 = doc[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:word.isdigit=%s' % word1.isdigit(),\n",
    "            '+1:postag=' + postag1\n",
    "        ])\n",
    "    # feature for a word which is the end of a document\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Making a Training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# generate features for a document\n",
    "def extract_features(doc):\n",
    "    return [word2features(doc, i) for i in range(len(doc))]\n",
    "\n",
    "# get labels of each token in a document\n",
    "def get_labels(doc):\n",
    "    return [label for (token, postag, label) in doc]\n",
    "\n",
    "X = [extract_features(doc) for doc in data]\n",
    "y = [get_labels(doc) for doc in data]\n",
    "\n",
    "# train-test set split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 6348\n",
      "Seconds required: 0.043\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.010000\n",
      "num_memories: 6\n",
      "max_iterations: 200\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "***** Iteration #1 *****\n",
      "Loss: 5235.067704\n",
      "Feature norm: 1.000000\n",
      "Error norm: 2048.867330\n",
      "Active features: 6324\n",
      "Line search trials: 1\n",
      "Line search step: 0.000042\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Iteration #2 *****\n",
      "Loss: 5079.912133\n",
      "Feature norm: 1.072351\n",
      "Error norm: 1430.589928\n",
      "Active features: 6102\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Iteration #3 *****\n",
      "Loss: 4843.885911\n",
      "Feature norm: 1.206059\n",
      "Error norm: 1462.374409\n",
      "Active features: 6052\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #4 *****\n",
      "Loss: 4425.646910\n",
      "Feature norm: 1.387009\n",
      "Error norm: 979.157327\n",
      "Active features: 6219\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #5 *****\n",
      "Loss: 3886.884365\n",
      "Feature norm: 2.355301\n",
      "Error norm: 2553.274913\n",
      "Active features: 6244\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #6 *****\n",
      "Loss: 3454.663294\n",
      "Feature norm: 2.658600\n",
      "Error norm: 818.799697\n",
      "Active features: 6213\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #7 *****\n",
      "Loss: 2939.892106\n",
      "Feature norm: 3.787743\n",
      "Error norm: 646.124488\n",
      "Active features: 5981\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #8 *****\n",
      "Loss: 2289.800299\n",
      "Feature norm: 5.824776\n",
      "Error norm: 481.302081\n",
      "Active features: 5096\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #9 *****\n",
      "Loss: 2102.777643\n",
      "Feature norm: 6.740555\n",
      "Error norm: 1673.382564\n",
      "Active features: 4841\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Iteration #10 *****\n",
      "Loss: 1905.184673\n",
      "Feature norm: 7.192338\n",
      "Error norm: 374.042970\n",
      "Active features: 4787\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #11 *****\n",
      "Loss: 1766.303122\n",
      "Feature norm: 8.086865\n",
      "Error norm: 766.725909\n",
      "Active features: 4631\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #12 *****\n",
      "Loss: 1585.302518\n",
      "Feature norm: 9.240284\n",
      "Error norm: 301.444894\n",
      "Active features: 4580\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #13 *****\n",
      "Loss: 1419.639091\n",
      "Feature norm: 11.662086\n",
      "Error norm: 885.723174\n",
      "Active features: 4318\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #14 *****\n",
      "Loss: 1286.366493\n",
      "Feature norm: 12.966802\n",
      "Error norm: 154.149474\n",
      "Active features: 4355\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #15 *****\n",
      "Loss: 1183.694084\n",
      "Feature norm: 15.206151\n",
      "Error norm: 392.245226\n",
      "Active features: 4338\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #16 *****\n",
      "Loss: 1074.850495\n",
      "Feature norm: 16.932541\n",
      "Error norm: 122.231437\n",
      "Active features: 4329\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #17 *****\n",
      "Loss: 970.285747\n",
      "Feature norm: 20.070455\n",
      "Error norm: 289.440199\n",
      "Active features: 4267\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #18 *****\n",
      "Loss: 907.078849\n",
      "Feature norm: 21.099061\n",
      "Error norm: 160.304842\n",
      "Active features: 4204\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #19 *****\n",
      "Loss: 839.722967\n",
      "Feature norm: 23.294937\n",
      "Error norm: 270.937731\n",
      "Active features: 4085\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #20 *****\n",
      "Loss: 782.592549\n",
      "Feature norm: 24.880624\n",
      "Error norm: 158.865039\n",
      "Active features: 3962\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #21 *****\n",
      "Loss: 721.371229\n",
      "Feature norm: 27.191204\n",
      "Error norm: 160.874603\n",
      "Active features: 3749\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #22 *****\n",
      "Loss: 660.840073\n",
      "Feature norm: 29.472444\n",
      "Error norm: 84.062824\n",
      "Active features: 3477\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #23 *****\n",
      "Loss: 602.704562\n",
      "Feature norm: 32.523246\n",
      "Error norm: 181.715222\n",
      "Active features: 3245\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #24 *****\n",
      "Loss: 561.464988\n",
      "Feature norm: 34.703000\n",
      "Error norm: 198.918285\n",
      "Active features: 3127\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Iteration #25 *****\n",
      "Loss: 527.614527\n",
      "Feature norm: 36.513338\n",
      "Error norm: 87.865461\n",
      "Active features: 3044\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #26 *****\n",
      "Loss: 497.134457\n",
      "Feature norm: 38.024536\n",
      "Error norm: 47.364595\n",
      "Active features: 2848\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #27 *****\n",
      "Loss: 468.014286\n",
      "Feature norm: 41.828798\n",
      "Error norm: 248.116275\n",
      "Active features: 2748\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #28 *****\n",
      "Loss: 448.483195\n",
      "Feature norm: 42.625620\n",
      "Error norm: 59.034242\n",
      "Active features: 2763\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #29 *****\n",
      "Loss: 437.712319\n",
      "Feature norm: 43.558183\n",
      "Error norm: 125.667077\n",
      "Active features: 2737\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #30 *****\n",
      "Loss: 426.559821\n",
      "Feature norm: 44.224475\n",
      "Error norm: 21.390273\n",
      "Active features: 2735\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #31 *****\n",
      "Loss: 411.147400\n",
      "Feature norm: 46.027497\n",
      "Error norm: 105.100883\n",
      "Active features: 2683\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #32 *****\n",
      "Loss: 401.485967\n",
      "Feature norm: 47.051046\n",
      "Error norm: 109.967241\n",
      "Active features: 2619\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #33 *****\n",
      "Loss: 393.765045\n",
      "Feature norm: 47.464611\n",
      "Error norm: 38.562482\n",
      "Active features: 2610\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #34 *****\n",
      "Loss: 387.862950\n",
      "Feature norm: 48.279102\n",
      "Error norm: 79.777111\n",
      "Active features: 2575\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #35 *****\n",
      "Loss: 382.202226\n",
      "Feature norm: 48.820963\n",
      "Error norm: 35.262966\n",
      "Active features: 2505\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #36 *****\n",
      "Loss: 378.524094\n",
      "Feature norm: 48.906444\n",
      "Error norm: 29.779243\n",
      "Active features: 2452\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #37 *****\n",
      "Loss: 373.664585\n",
      "Feature norm: 48.696280\n",
      "Error norm: 17.074789\n",
      "Active features: 2402\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #38 *****\n",
      "Loss: 369.458680\n",
      "Feature norm: 48.704962\n",
      "Error norm: 65.821276\n",
      "Active features: 2311\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #39 *****\n",
      "Loss: 364.760308\n",
      "Feature norm: 48.695402\n",
      "Error norm: 47.954380\n",
      "Active features: 2248\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #40 *****\n",
      "Loss: 362.710080\n",
      "Feature norm: 48.877689\n",
      "Error norm: 35.812066\n",
      "Active features: 2226\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #41 *****\n",
      "Loss: 360.111231\n",
      "Feature norm: 49.142779\n",
      "Error norm: 48.659317\n",
      "Active features: 2218\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #42 *****\n",
      "Loss: 356.734783\n",
      "Feature norm: 49.709282\n",
      "Error norm: 54.733947\n",
      "Active features: 2179\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #43 *****\n",
      "Loss: 354.363975\n",
      "Feature norm: 50.215368\n",
      "Error norm: 68.919253\n",
      "Active features: 2132\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #44 *****\n",
      "Loss: 352.395400\n",
      "Feature norm: 50.461877\n",
      "Error norm: 25.790519\n",
      "Active features: 2134\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #45 *****\n",
      "Loss: 351.095141\n",
      "Feature norm: 50.803584\n",
      "Error norm: 28.034044\n",
      "Active features: 2112\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #46 *****\n",
      "Loss: 349.162296\n",
      "Feature norm: 51.087849\n",
      "Error norm: 12.592920\n",
      "Active features: 2102\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #47 *****\n",
      "Loss: 347.951634\n",
      "Feature norm: 51.896465\n",
      "Error norm: 89.198649\n",
      "Active features: 2049\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #48 *****\n",
      "Loss: 345.561833\n",
      "Feature norm: 52.004385\n",
      "Error norm: 26.632162\n",
      "Active features: 2042\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #49 *****\n",
      "Loss: 344.570176\n",
      "Feature norm: 52.253097\n",
      "Error norm: 33.058788\n",
      "Active features: 2035\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #50 *****\n",
      "Loss: 343.492333\n",
      "Feature norm: 52.370070\n",
      "Error norm: 22.504016\n",
      "Active features: 2020\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #51 *****\n",
      "Loss: 342.322170\n",
      "Feature norm: 52.670273\n",
      "Error norm: 34.416175\n",
      "Active features: 1999\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #52 *****\n",
      "Loss: 341.484044\n",
      "Feature norm: 52.805088\n",
      "Error norm: 35.923599\n",
      "Active features: 1987\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #53 *****\n",
      "Loss: 340.563310\n",
      "Feature norm: 53.078198\n",
      "Error norm: 27.625157\n",
      "Active features: 1982\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #54 *****\n",
      "Loss: 339.751836\n",
      "Feature norm: 53.157013\n",
      "Error norm: 15.364244\n",
      "Active features: 1977\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #55 *****\n",
      "Loss: 338.964819\n",
      "Feature norm: 53.394352\n",
      "Error norm: 35.347457\n",
      "Active features: 1964\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Iteration #56 *****\n",
      "Loss: 338.263990\n",
      "Feature norm: 53.478264\n",
      "Error norm: 35.393060\n",
      "Active features: 1952\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #57 *****\n",
      "Loss: 337.452382\n",
      "Feature norm: 53.698422\n",
      "Error norm: 31.001760\n",
      "Active features: 1950\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #58 *****\n",
      "Loss: 336.802475\n",
      "Feature norm: 53.732467\n",
      "Error norm: 18.709437\n",
      "Active features: 1936\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #59 *****\n",
      "Loss: 336.255449\n",
      "Feature norm: 53.888110\n",
      "Error norm: 26.815902\n",
      "Active features: 1918\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Iteration #60 *****\n",
      "Loss: 335.715379\n",
      "Feature norm: 53.924697\n",
      "Error norm: 24.095040\n",
      "Active features: 1909\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #61 *****\n",
      "Loss: 335.224087\n",
      "Feature norm: 54.064029\n",
      "Error norm: 29.426719\n",
      "Active features: 1902\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #62 *****\n",
      "Loss: 334.712243\n",
      "Feature norm: 54.087349\n",
      "Error norm: 18.123949\n",
      "Active features: 1900\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #63 *****\n",
      "Loss: 334.271803\n",
      "Feature norm: 54.169419\n",
      "Error norm: 24.317654\n",
      "Active features: 1899\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #64 *****\n",
      "Loss: 333.721763\n",
      "Feature norm: 54.201890\n",
      "Error norm: 23.462653\n",
      "Active features: 1886\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #65 *****\n",
      "Loss: 333.250400\n",
      "Feature norm: 54.302128\n",
      "Error norm: 29.076430\n",
      "Active features: 1873\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #66 *****\n",
      "Loss: 332.718820\n",
      "Feature norm: 54.318381\n",
      "Error norm: 23.162112\n",
      "Active features: 1857\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #67 *****\n",
      "Loss: 332.324119\n",
      "Feature norm: 54.402107\n",
      "Error norm: 27.260139\n",
      "Active features: 1848\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #68 *****\n",
      "Loss: 331.828165\n",
      "Feature norm: 54.405777\n",
      "Error norm: 18.241316\n",
      "Active features: 1840\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #69 *****\n",
      "Loss: 331.429559\n",
      "Feature norm: 54.512439\n",
      "Error norm: 24.640821\n",
      "Active features: 1835\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #70 *****\n",
      "Loss: 331.018649\n",
      "Feature norm: 54.548710\n",
      "Error norm: 20.305658\n",
      "Active features: 1832\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #71 *****\n",
      "Loss: 330.685618\n",
      "Feature norm: 54.680737\n",
      "Error norm: 24.770196\n",
      "Active features: 1826\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #72 *****\n",
      "Loss: 330.332282\n",
      "Feature norm: 54.723191\n",
      "Error norm: 18.052470\n",
      "Active features: 1824\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #73 *****\n",
      "Loss: 329.997632\n",
      "Feature norm: 54.850507\n",
      "Error norm: 21.688088\n",
      "Active features: 1815\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #74 *****\n",
      "Loss: 329.669530\n",
      "Feature norm: 54.885062\n",
      "Error norm: 24.483166\n",
      "Active features: 1810\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #75 *****\n",
      "Loss: 329.358186\n",
      "Feature norm: 55.040946\n",
      "Error norm: 25.005740\n",
      "Active features: 1805\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #76 *****\n",
      "Loss: 329.019238\n",
      "Feature norm: 55.055658\n",
      "Error norm: 21.226550\n",
      "Active features: 1799\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #77 *****\n",
      "Loss: 328.754450\n",
      "Feature norm: 55.194905\n",
      "Error norm: 20.356812\n",
      "Active features: 1802\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #78 *****\n",
      "Loss: 328.462658\n",
      "Feature norm: 55.210464\n",
      "Error norm: 17.899878\n",
      "Active features: 1793\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #79 *****\n",
      "Loss: 328.183031\n",
      "Feature norm: 55.284803\n",
      "Error norm: 18.454490\n",
      "Active features: 1793\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #80 *****\n",
      "Loss: 327.976367\n",
      "Feature norm: 55.308254\n",
      "Error norm: 23.454468\n",
      "Active features: 1781\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #81 *****\n",
      "Loss: 327.701995\n",
      "Feature norm: 55.421450\n",
      "Error norm: 22.716405\n",
      "Active features: 1771\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #82 *****\n",
      "Loss: 327.448327\n",
      "Feature norm: 55.430857\n",
      "Error norm: 16.083504\n",
      "Active features: 1769\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #83 *****\n",
      "Loss: 327.229171\n",
      "Feature norm: 55.506690\n",
      "Error norm: 16.573963\n",
      "Active features: 1766\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #84 *****\n",
      "Loss: 326.996882\n",
      "Feature norm: 55.511856\n",
      "Error norm: 16.214649\n",
      "Active features: 1756\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #85 *****\n",
      "Loss: 326.786002\n",
      "Feature norm: 55.606073\n",
      "Error norm: 20.451098\n",
      "Active features: 1747\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #86 *****\n",
      "Loss: 326.577490\n",
      "Feature norm: 55.594806\n",
      "Error norm: 19.644904\n",
      "Active features: 1742\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #87 *****\n",
      "Loss: 326.388085\n",
      "Feature norm: 55.697083\n",
      "Error norm: 18.304549\n",
      "Active features: 1740\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #88 *****\n",
      "Loss: 326.182063\n",
      "Feature norm: 55.703435\n",
      "Error norm: 14.958628\n",
      "Active features: 1737\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #89 *****\n",
      "Loss: 325.990618\n",
      "Feature norm: 55.764444\n",
      "Error norm: 12.539563\n",
      "Active features: 1733\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #90 *****\n",
      "Loss: 325.813033\n",
      "Feature norm: 55.787897\n",
      "Error norm: 17.155352\n",
      "Active features: 1730\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #91 *****\n",
      "Loss: 325.651009\n",
      "Feature norm: 55.876850\n",
      "Error norm: 20.905738\n",
      "Active features: 1723\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #92 *****\n",
      "Loss: 325.426680\n",
      "Feature norm: 55.891555\n",
      "Error norm: 17.142675\n",
      "Active features: 1718\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #93 *****\n",
      "Loss: 325.258062\n",
      "Feature norm: 55.978892\n",
      "Error norm: 16.783439\n",
      "Active features: 1711\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #94 *****\n",
      "Loss: 325.053146\n",
      "Feature norm: 55.984176\n",
      "Error norm: 13.927765\n",
      "Active features: 1701\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #95 *****\n",
      "Loss: 324.893812\n",
      "Feature norm: 56.056528\n",
      "Error norm: 15.777306\n",
      "Active features: 1698\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #96 *****\n",
      "Loss: 324.722388\n",
      "Feature norm: 56.069557\n",
      "Error norm: 19.467303\n",
      "Active features: 1695\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #97 *****\n",
      "Loss: 324.562348\n",
      "Feature norm: 56.132001\n",
      "Error norm: 13.894058\n",
      "Active features: 1693\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #98 *****\n",
      "Loss: 324.402139\n",
      "Feature norm: 56.135136\n",
      "Error norm: 12.258255\n",
      "Active features: 1697\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #99 *****\n",
      "Loss: 324.232465\n",
      "Feature norm: 56.164684\n",
      "Error norm: 8.254358\n",
      "Active features: 1691\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #100 *****\n",
      "Loss: 324.058607\n",
      "Feature norm: 56.185921\n",
      "Error norm: 15.110498\n",
      "Active features: 1678\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #101 *****\n",
      "Loss: 323.895792\n",
      "Feature norm: 56.232176\n",
      "Error norm: 16.813960\n",
      "Active features: 1670\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #102 *****\n",
      "Loss: 323.718890\n",
      "Feature norm: 56.233050\n",
      "Error norm: 11.990159\n",
      "Active features: 1664\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #103 *****\n",
      "Loss: 323.576989\n",
      "Feature norm: 56.267894\n",
      "Error norm: 12.490590\n",
      "Active features: 1661\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #104 *****\n",
      "Loss: 323.442193\n",
      "Feature norm: 56.272470\n",
      "Error norm: 15.886807\n",
      "Active features: 1658\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #105 *****\n",
      "Loss: 323.296254\n",
      "Feature norm: 56.324678\n",
      "Error norm: 16.710164\n",
      "Active features: 1654\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #106 *****\n",
      "Loss: 323.155408\n",
      "Feature norm: 56.318397\n",
      "Error norm: 17.278147\n",
      "Active features: 1649\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #107 *****\n",
      "Loss: 323.006215\n",
      "Feature norm: 56.374213\n",
      "Error norm: 14.289131\n",
      "Active features: 1644\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #108 *****\n",
      "Loss: 322.890541\n",
      "Feature norm: 56.370617\n",
      "Error norm: 12.586444\n",
      "Active features: 1639\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #109 *****\n",
      "Loss: 322.785003\n",
      "Feature norm: 56.400781\n",
      "Error norm: 9.685746\n",
      "Active features: 1638\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #110 *****\n",
      "Loss: 322.672294\n",
      "Feature norm: 56.405282\n",
      "Error norm: 8.423812\n",
      "Active features: 1635\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #111 *****\n",
      "Loss: 322.554451\n",
      "Feature norm: 56.425941\n",
      "Error norm: 13.120895\n",
      "Active features: 1625\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #112 *****\n",
      "Loss: 322.485460\n",
      "Feature norm: 56.411238\n",
      "Error norm: 18.723230\n",
      "Active features: 1623\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #113 *****\n",
      "Loss: 322.338666\n",
      "Feature norm: 56.449480\n",
      "Error norm: 13.149600\n",
      "Active features: 1616\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #114 *****\n",
      "Loss: 322.234875\n",
      "Feature norm: 56.440579\n",
      "Error norm: 10.496958\n",
      "Active features: 1615\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Iteration #115 *****\n",
      "Loss: 322.136245\n",
      "Feature norm: 56.455294\n",
      "Error norm: 5.995263\n",
      "Active features: 1612\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Iteration #116 *****\n",
      "Loss: 322.026596\n",
      "Feature norm: 56.439184\n",
      "Error norm: 9.940872\n",
      "Active features: 1609\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.015\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Iteration #117 *****\n",
      "Loss: 321.932015\n",
      "Feature norm: 56.455303\n",
      "Error norm: 16.566333\n",
      "Active features: 1603\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Iteration #118 *****\n",
      "Loss: 321.805564\n",
      "Feature norm: 56.423620\n",
      "Error norm: 14.322200\n",
      "Active features: 1602\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Iteration #119 *****\n",
      "Loss: 321.700959\n",
      "Feature norm: 56.447185\n",
      "Error norm: 8.759635\n",
      "Active features: 1603\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Iteration #120 *****\n",
      "Loss: 321.594153\n",
      "Feature norm: 56.432973\n",
      "Error norm: 7.874820\n",
      "Active features: 1597\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #121 *****\n",
      "Loss: 321.461184\n",
      "Feature norm: 56.435953\n",
      "Error norm: 7.507584\n",
      "Active features: 1593\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Iteration #122 *****\n",
      "Loss: 321.413542\n",
      "Feature norm: 56.399294\n",
      "Error norm: 22.240331\n",
      "Active features: 1577\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #123 *****\n",
      "Loss: 321.233686\n",
      "Feature norm: 56.440578\n",
      "Error norm: 9.259550\n",
      "Active features: 1576\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Iteration #124 *****\n",
      "Loss: 321.146910\n",
      "Feature norm: 56.419391\n",
      "Error norm: 7.112752\n",
      "Active features: 1577\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #125 *****\n",
      "Loss: 321.047504\n",
      "Feature norm: 56.423925\n",
      "Error norm: 6.277506\n",
      "Active features: 1573\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #126 *****\n",
      "Loss: 320.915860\n",
      "Feature norm: 56.380797\n",
      "Error norm: 9.093153\n",
      "Active features: 1565\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #127 *****\n",
      "Loss: 320.913601\n",
      "Feature norm: 56.406324\n",
      "Error norm: 24.111717\n",
      "Active features: 1561\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #128 *****\n",
      "Loss: 320.730074\n",
      "Feature norm: 56.372109\n",
      "Error norm: 3.192613\n",
      "Active features: 1566\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #129 *****\n",
      "Loss: 320.654308\n",
      "Feature norm: 56.371577\n",
      "Error norm: 5.494574\n",
      "Active features: 1567\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #130 *****\n",
      "Loss: 320.571821\n",
      "Feature norm: 56.345140\n",
      "Error norm: 14.696176\n",
      "Active features: 1556\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #131 *****\n",
      "Loss: 320.497301\n",
      "Feature norm: 56.363682\n",
      "Error norm: 16.079059\n",
      "Active features: 1550\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #132 *****\n",
      "Loss: 320.402640\n",
      "Feature norm: 56.344982\n",
      "Error norm: 3.823297\n",
      "Active features: 1551\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #133 *****\n",
      "Loss: 320.333264\n",
      "Feature norm: 56.339654\n",
      "Error norm: 2.526338\n",
      "Active features: 1551\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #134 *****\n",
      "Loss: 320.169516\n",
      "Feature norm: 56.300782\n",
      "Error norm: 3.789405\n",
      "Active features: 1534\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #135 *****\n",
      "Loss: 320.055870\n",
      "Feature norm: 56.299376\n",
      "Error norm: 8.125262\n",
      "Active features: 1536\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #136 *****\n",
      "Loss: 319.979918\n",
      "Feature norm: 56.265239\n",
      "Error norm: 10.919046\n",
      "Active features: 1540\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #137 *****\n",
      "Loss: 319.958734\n",
      "Feature norm: 56.286765\n",
      "Error norm: 20.928126\n",
      "Active features: 1539\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #138 *****\n",
      "Loss: 319.838064\n",
      "Feature norm: 56.236754\n",
      "Error norm: 12.806085\n",
      "Active features: 1540\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #139 *****\n",
      "Loss: 319.793193\n",
      "Feature norm: 56.257500\n",
      "Error norm: 15.285864\n",
      "Active features: 1535\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #140 *****\n",
      "Loss: 319.696721\n",
      "Feature norm: 56.229939\n",
      "Error norm: 7.884088\n",
      "Active features: 1532\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #141 *****\n",
      "Loss: 319.658482\n",
      "Feature norm: 56.245628\n",
      "Error norm: 11.326421\n",
      "Active features: 1530\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #142 *****\n",
      "Loss: 319.590746\n",
      "Feature norm: 56.226932\n",
      "Error norm: 11.378770\n",
      "Active features: 1530\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #143 *****\n",
      "Loss: 319.558504\n",
      "Feature norm: 56.246031\n",
      "Error norm: 13.879249\n",
      "Active features: 1537\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #144 *****\n",
      "Loss: 319.482995\n",
      "Feature norm: 56.217157\n",
      "Error norm: 12.089230\n",
      "Active features: 1534\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #145 *****\n",
      "Loss: 319.438262\n",
      "Feature norm: 56.233599\n",
      "Error norm: 10.702911\n",
      "Active features: 1533\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #146 *****\n",
      "Loss: 319.370093\n",
      "Feature norm: 56.211681\n",
      "Error norm: 9.391247\n",
      "Active features: 1533\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #147 *****\n",
      "Loss: 319.299452\n",
      "Feature norm: 56.215383\n",
      "Error norm: 7.967746\n",
      "Active features: 1534\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #148 *****\n",
      "Loss: 319.261807\n",
      "Feature norm: 56.178049\n",
      "Error norm: 14.289891\n",
      "Active features: 1528\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Iteration #149 *****\n",
      "Loss: 319.205841\n",
      "Feature norm: 56.198319\n",
      "Error norm: 15.398266\n",
      "Active features: 1523\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Iteration #150 *****\n",
      "Loss: 319.132838\n",
      "Feature norm: 56.161624\n",
      "Error norm: 10.318431\n",
      "Active features: 1523\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #151 *****\n",
      "Loss: 319.084440\n",
      "Feature norm: 56.167308\n",
      "Error norm: 11.743650\n",
      "Active features: 1522\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #152 *****\n",
      "Loss: 319.030546\n",
      "Feature norm: 56.138812\n",
      "Error norm: 5.741023\n",
      "Active features: 1518\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #153 *****\n",
      "Loss: 318.996131\n",
      "Feature norm: 56.138866\n",
      "Error norm: 10.582435\n",
      "Active features: 1516\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #154 *****\n",
      "Loss: 318.941212\n",
      "Feature norm: 56.119979\n",
      "Error norm: 6.895053\n",
      "Active features: 1515\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #155 *****\n",
      "Loss: 318.930297\n",
      "Feature norm: 56.123210\n",
      "Error norm: 15.868323\n",
      "Active features: 1511\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #156 *****\n",
      "Loss: 318.857361\n",
      "Feature norm: 56.099863\n",
      "Error norm: 9.033220\n",
      "Active features: 1509\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #157 *****\n",
      "Loss: 318.827245\n",
      "Feature norm: 56.107728\n",
      "Error norm: 14.544033\n",
      "Active features: 1515\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #158 *****\n",
      "Loss: 318.765469\n",
      "Feature norm: 56.086750\n",
      "Error norm: 8.226696\n",
      "Active features: 1514\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #159 *****\n",
      "Loss: 318.743514\n",
      "Feature norm: 56.094000\n",
      "Error norm: 14.125953\n",
      "Active features: 1514\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #160 *****\n",
      "Loss: 318.673855\n",
      "Feature norm: 56.078518\n",
      "Error norm: 5.159682\n",
      "Active features: 1510\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #161 *****\n",
      "Loss: 318.662941\n",
      "Feature norm: 56.082337\n",
      "Error norm: 13.527860\n",
      "Active features: 1506\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #162 *****\n",
      "Loss: 318.593659\n",
      "Feature norm: 56.069995\n",
      "Error norm: 5.229224\n",
      "Active features: 1507\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #163 *****\n",
      "Loss: 318.563393\n",
      "Feature norm: 56.072920\n",
      "Error norm: 6.286885\n",
      "Active features: 1506\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Iteration #164 *****\n",
      "Loss: 318.502158\n",
      "Feature norm: 56.058477\n",
      "Error norm: 8.988589\n",
      "Active features: 1503\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #165 *****\n",
      "Loss: 318.444263\n",
      "Feature norm: 56.063433\n",
      "Error norm: 5.843003\n",
      "Active features: 1504\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Iteration #166 *****\n",
      "Loss: 318.401877\n",
      "Feature norm: 56.051289\n",
      "Error norm: 7.165765\n",
      "Active features: 1504\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Iteration #167 *****\n",
      "Loss: 318.361202\n",
      "Feature norm: 56.054239\n",
      "Error norm: 9.536741\n",
      "Active features: 1506\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Iteration #168 *****\n",
      "Loss: 318.318318\n",
      "Feature norm: 56.036611\n",
      "Error norm: 8.372787\n",
      "Active features: 1503\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Iteration #169 *****\n",
      "Loss: 318.274912\n",
      "Feature norm: 56.043371\n",
      "Error norm: 8.499009\n",
      "Active features: 1501\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Iteration #170 *****\n",
      "Loss: 318.235019\n",
      "Feature norm: 56.028063\n",
      "Error norm: 6.382162\n",
      "Active features: 1500\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Iteration #171 *****\n",
      "Loss: 318.193853\n",
      "Feature norm: 56.034582\n",
      "Error norm: 6.809405\n",
      "Active features: 1494\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.013\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Iteration #172 *****\n",
      "Loss: 318.158308\n",
      "Feature norm: 56.021550\n",
      "Error norm: 6.064301\n",
      "Active features: 1493\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Iteration #173 *****\n",
      "Loss: 318.124850\n",
      "Feature norm: 56.030538\n",
      "Error norm: 7.992801\n",
      "Active features: 1494\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Iteration #174 *****\n",
      "Loss: 318.086129\n",
      "Feature norm: 56.013324\n",
      "Error norm: 5.737443\n",
      "Active features: 1492\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Iteration #175 *****\n",
      "Loss: 318.052673\n",
      "Feature norm: 56.019348\n",
      "Error norm: 7.809929\n",
      "Active features: 1492\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Iteration #176 *****\n",
      "Loss: 318.010710\n",
      "Feature norm: 56.001157\n",
      "Error norm: 4.564454\n",
      "Active features: 1491\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Iteration #177 *****\n",
      "Loss: 317.986486\n",
      "Feature norm: 56.009543\n",
      "Error norm: 8.425109\n",
      "Active features: 1489\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Iteration #178 *****\n",
      "Loss: 317.946930\n",
      "Feature norm: 55.985032\n",
      "Error norm: 4.553615\n",
      "Active features: 1489\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Iteration #179 *****\n",
      "Loss: 317.919920\n",
      "Feature norm: 55.989336\n",
      "Error norm: 7.200067\n",
      "Active features: 1487\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Iteration #180 *****\n",
      "Loss: 317.916776\n",
      "Feature norm: 55.950864\n",
      "Error norm: 13.597670\n",
      "Active features: 1490\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #181 *****\n",
      "Loss: 317.858278\n",
      "Feature norm: 55.972693\n",
      "Error norm: 12.459157\n",
      "Active features: 1491\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #182 *****\n",
      "Loss: 317.805852\n",
      "Feature norm: 55.946411\n",
      "Error norm: 6.064059\n",
      "Active features: 1497\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #183 *****\n",
      "Loss: 317.789158\n",
      "Feature norm: 55.954868\n",
      "Error norm: 10.103612\n",
      "Active features: 1494\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #184 *****\n",
      "Loss: 317.750215\n",
      "Feature norm: 55.941296\n",
      "Error norm: 3.740552\n",
      "Active features: 1497\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #185 *****\n",
      "Loss: 317.741510\n",
      "Feature norm: 55.947694\n",
      "Error norm: 11.173500\n",
      "Active features: 1494\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #186 *****\n",
      "Loss: 317.699447\n",
      "Feature norm: 55.929942\n",
      "Error norm: 5.535383\n",
      "Active features: 1494\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #187 *****\n",
      "Loss: 317.694505\n",
      "Feature norm: 55.943256\n",
      "Error norm: 12.598117\n",
      "Active features: 1491\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #188 *****\n",
      "Loss: 317.644152\n",
      "Feature norm: 55.925205\n",
      "Error norm: 5.911763\n",
      "Active features: 1488\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #189 *****\n",
      "Loss: 317.635478\n",
      "Feature norm: 55.936823\n",
      "Error norm: 12.039243\n",
      "Active features: 1486\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #190 *****\n",
      "Loss: 317.584064\n",
      "Feature norm: 55.921201\n",
      "Error norm: 4.942922\n",
      "Active features: 1488\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Iteration #191 *****\n",
      "Loss: 317.560825\n",
      "Feature norm: 55.924635\n",
      "Error norm: 4.290573\n",
      "Active features: 1488\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Iteration #192 *****\n",
      "Loss: 317.532505\n",
      "Feature norm: 55.919038\n",
      "Error norm: 7.809545\n",
      "Active features: 1487\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #193 *****\n",
      "Loss: 317.494720\n",
      "Feature norm: 55.920603\n",
      "Error norm: 4.428891\n",
      "Active features: 1487\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Iteration #194 *****\n",
      "Loss: 317.484508\n",
      "Feature norm: 55.899747\n",
      "Error norm: 13.524877\n",
      "Active features: 1488\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #195 *****\n",
      "Loss: 317.446963\n",
      "Feature norm: 55.922998\n",
      "Error norm: 13.137652\n",
      "Active features: 1485\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #196 *****\n",
      "Loss: 317.394973\n",
      "Feature norm: 55.900016\n",
      "Error norm: 10.175853\n",
      "Active features: 1484\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #197 *****\n",
      "Loss: 317.364084\n",
      "Feature norm: 55.912549\n",
      "Error norm: 8.860075\n",
      "Active features: 1487\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #198 *****\n",
      "Loss: 317.321776\n",
      "Feature norm: 55.901981\n",
      "Error norm: 4.303899\n",
      "Active features: 1486\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #199 *****\n",
      "Loss: 317.306204\n",
      "Feature norm: 55.910601\n",
      "Error norm: 9.282162\n",
      "Active features: 1488\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Iteration #200 *****\n",
      "Loss: 317.281777\n",
      "Feature norm: 55.895301\n",
      "Error norm: 8.465954\n",
      "Active features: 1485\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 1.467\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 1485 (6348)\n",
      "Number of active attributes: 788 (5148)\n",
      "Number of active labels: 8 (8)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pycrfsuite\n",
    "trainer = pycrfsuite.Trainer(verbose=True) #verbose = False (-> do not print the process of training)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)\n",
    "\n",
    "# Set the parameters of the model\n",
    "trainer.set_params({\n",
    "    # coefficient for L1 penalty\n",
    "    'c1': 0.1,\n",
    "\n",
    "    # coefficient for L2 penalty\n",
    "    'c2': 0.01,  \n",
    "\n",
    "    # maximum number of iterations\n",
    "    'max_iterations': 200,\n",
    "\n",
    "    # whether to include transitions that\n",
    "    # are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})\n",
    "\n",
    "# set the file name of model, which will be saved\n",
    "trainer.train('crf.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Results\n",
    "\n",
    "### 3-1. prediction\n",
    "* tagger.tag() performs prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('crf.model')\n",
    "y_pred = [tagger.tag(xseq) for xseq in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X',\n",
       " 'B-nparam',\n",
       " 'I-nparam',\n",
       " 'I-nparam',\n",
       " 'I-nparam',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X',\n",
       " 'X']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. check the result\n",
    "\n",
    "* comparing..\n",
    "    * tokens that is __labeld__ as parameters (and)\n",
    "    * tokens that is __predicted__ as parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_testset = len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<< Test number 0 >> \n",
      " [ Sentence ]  returns true if for every '*' (star) in the string, if there are chars both immediately before and after the star, they are the same. \n",
      "  - Real Arguments :  ['string, ']\n",
      "  - Predicted Arguments :  ['string, ']\n",
      "\n",
      "<< Test number 1 >> \n",
      " [ Sentence ]  given two non-negative int values, return true if they have the same last digit, such as with 27 and 57. note that the % \"mod\" operator computes remainders, so 17 % 10 is 7. \n",
      "  - Real Arguments :  ['two non-negative int values, ']\n",
      "  - Predicted Arguments :  ['two non-negative int values, ']\n",
      "\n",
      "<< Test number 2 >> \n",
      " [ Sentence ]  given a string and a non-empty substring sub, compute recursively the number of times that sub appears in the string, without the sub strings overlapping. \n",
      "  - Real Arguments :  ['string ', 'sub, ', 'sub ', 'string, ', 'sub strings ']\n",
      "  - Predicted Arguments :  ['string ', 'non-empty substring sub, ', 'string, ', 'sub ']\n",
      "\n",
      "<< Test number 3 >> \n",
      " [ Sentence ]  loop over the given array of strings to build a result string like this: when a string appears the 2nd, 4th, 6th, etc. time in the array, append the string to the result. return the empty string if no string appears a 2nd time. \n",
      "  - Real Arguments :  ['array of strings ', 'array, ']\n",
      "  - Predicted Arguments :  ['array of strings ', 'array, ', 'string ']\n",
      "\n",
      "<< Test number 4 >> \n",
      " [ Sentence ]  given a list of strings, return a list where each string has \"*\" added at its end. \n",
      "  - Real Arguments :  ['list of strings, ']\n",
      "  - Predicted Arguments :  ['list of strings, ']\n",
      "\n",
      "<< Test number 5 >> \n",
      " [ Sentence ]  count recursively the total number of \"abc\" and \"aba\" substrings that appear in the given string. \n",
      "  - Real Arguments :  []\n",
      "  - Predicted Arguments :  []\n",
      "\n",
      "<< Test number 6 >> \n",
      " [ Sentence ]  we'll say that a string is xy-balanced if for all the 'x' chars in the string, there exists a 'y' char somewhere later in the string. so \"xxy\" is balanced, but \"xyx\" is not. one 'y' can balance multiple 'x's. return true if the given string is xy-balanced. \n",
      "  - Real Arguments :  ['string, ', 'string. ', 'string ']\n",
      "  - Predicted Arguments :  ['string, ', 'string. ', 'string ']\n",
      "\n",
      "<< Test number 7 >> \n",
      " [ Sentence ]  return true if the given string begins with \"mix\", except the 'm' can be anything, so \"pix\", \"9ix\" .. all count. \n",
      "  - Real Arguments :  ['string ']\n",
      "  - Predicted Arguments :  ['string ']\n",
      "\n",
      "<< Test number 8 >> \n",
      " [ Sentence ]  given an array of ints, return the number of 9's in the array. \n",
      "  - Real Arguments :  ['array of ints, ']\n",
      "  - Predicted Arguments :  ['array of ints, ']\n",
      "\n",
      "<< Test number 9 >> \n",
      " [ Sentence ]  given a string, compute recursively a new string where all the 'x' chars have been removed. \n",
      "  - Real Arguments :  ['string, ']\n",
      "  - Predicted Arguments :  ['string, ']\n",
      "\n",
      "<< Test number 10 >> \n",
      " [ Sentence ]  return an int array length 3 containing the first 3 digits of pi, {3, 1, 4}. \n",
      "  - Real Arguments :  []\n",
      "  - Predicted Arguments :  ['int array ']\n",
      "\n",
      "<< Test number 11 >> \n",
      " [ Sentence ]  we'll say that a number is \"teen\" if it is in the range 13..19 inclusive. given 2 int values, return true if one or the other is teen, but not both. \n",
      "  - Real Arguments :  ['2 int values, ', 'one ', 'the other ']\n",
      "  - Predicted Arguments :  ['2 int values, ']\n",
      "\n",
      "<< Test number 12 >> \n",
      " [ Sentence ]  given a string, return the longest substring that appears at both the beginning and end of the string without overlapping. for example, sameends(\"abxab\") is \"ab\". \n",
      "  - Real Arguments :  ['string, ', 'string ']\n",
      "  - Predicted Arguments :  ['string, ', 'string ']\n",
      "\n",
      "<< Test number 13 >> \n",
      " [ Sentence ]  given a string and an int n, return a string made of n repetitions of the last n characters of the string. you may assume that n is between 0 and the length of the string, inclusive. \n",
      "  - Real Arguments :  ['string ', 'int n, ', 'n ', 'n ', 'n ', 'string, ']\n",
      "  - Predicted Arguments :  ['string ', 'int n, ', 'n ', 'string. ', 'n ', 'string, ']\n",
      "\n",
      "<< Test number 14 >> \n",
      " [ Sentence ]  given start and end numbers, return a new array containing the sequence of integers from start up to but not including end, so start and end yields {5, 6, 7, 8, 9}. the end number will be greater or equal to the start number. note that a length-0 array is valid. (see also: fizzbuzz code) \n",
      "  - Real Arguments :  ['start ', 'end ', 'start ', 'end, ', 'end ', 'start ']\n",
      "  - Predicted Arguments :  ['start ', 'numbers, ']\n",
      "\n",
      "<< Test number 15 >> \n",
      " [ Sentence ]  given 2 int values, return whichever value is nearest to the value 10, or return 0 in the event of a tie. note that math.abs(n) returns the absolute value of a number. \n",
      "  - Real Arguments :  ['2 int values, ']\n",
      "  - Predicted Arguments :  ['2 int values, ']\n",
      "\n",
      "<< Test number 16 >> \n",
      " [ Sentence ]  we have triangle made of blocks. the topmost row has 1 block, the next row down has 2 blocks, the next row has 3 blocks, and so on. compute recursively (no loops or multiplication) the total number of blocks in such a triangle with the given number of rows. \n",
      "  - Real Arguments :  []\n",
      "  - Predicted Arguments :  ['number ']\n",
      "\n",
      "<< Test number 17 >> \n",
      " [ Sentence ]  given a string, if the string begins with \"red\" or \"blue\" return that color string, otherwise return the empty string. \n",
      "  - Real Arguments :  ['string, ', 'string ']\n",
      "  - Predicted Arguments :  ['string, ', 'string ']\n",
      "\n",
      "<< Test number 18 >> \n",
      " [ Sentence ]  you have a green lottery ticket, with ints a, b, and c on it. if the numbers are all different from each other, the result is 0. if all of the numbers are the same, the result is 20. if two of the numbers are the same, the result is 10. \n",
      "  - Real Arguments :  ['ints ', 'a, ', 'b, ', 'c ', 'numbers ', 'all of the numbers ', 'two of the numbers ']\n",
      "  - Predicted Arguments :  ['two of the numbers ']\n",
      "\n",
      "<< Test number 19 >> \n",
      " [ Sentence ]  given a string str, if the string starts with \"f\" return \"fizz\". if the string ends with \"b\" return \"buzz\". if both the \"f\" and \"b\" conditions are true, return \"fizzbuzz\". in all other cases, return the string unchanged. (see also: fizzbuzz code) \n",
      "  - Real Arguments :  ['string str, ', 'the string ', 'the string ', 'the string ']\n",
      "  - Predicted Arguments :  ['string ', 'string ', 'other cases, ', 'string ']\n",
      "\n",
      "<< Test number 20 >> \n",
      " [ Sentence ]  given an array of ints, is it possible to choose a group of some of the ints, such that the group sums to the given target? this is a classic backtracking recursion problem. once you understand the recursive backtracking strategy in this problem, you can use the same pattern for many problems to search a space of choices. rather than looking at the whole array, our convention is to consider the part of the array starting at index start and continuing to the end of the array. the caller can specify the whole array simply by passing start as 0. no loops are needed -- the recursive calls progress down the array. \n",
      "  - Real Arguments :  ['array of ints, ', 'target? ', 'array, ', 'array ', 'start ', 'array. ', 'array ', 'start ']\n",
      "  - Predicted Arguments :  ['array of ints, ', 'target? ', 'array ', 'array. ']\n",
      "\n",
      "<< Test number 21 >> \n",
      " [ Sentence ]  given 3 int values, a b c, return their sum. however, if one of the values is the same as another of the values, it does not count towards the sum. \n",
      "  - Real Arguments :  ['3 int values, ', 'a ', 'b ', 'c, ', 'one of the values ', 'another of the values, ']\n",
      "  - Predicted Arguments :  ['3 int values, ', 'a ', 'b ', 'c, ', 'one of the values ']\n",
      "\n",
      "<< Test number 22 >> \n",
      " [ Sentence ]  given two strings, base and remove, return a version of the base string where all instances of the remove string have been removed (not case sensitive). you may assume that the remove string is length 1 or more. remove only non-overlapping instances, so with \"xxx\" removing \"xx\" leaves \"x\". \n",
      "  - Real Arguments :  ['two strings, ', 'base ', 'remove, ', 'base string ', 'remove string ', 'remove string ']\n",
      "  - Predicted Arguments :  ['two strings, ', 'base ', 'base ']\n",
      "\n",
      "<< Test number 23 >> \n",
      " [ Sentence ]  suppose the string \"yak\" is unlucky. given a string, return a version where all the \"yak\" are removed, but the \"a\" can be any char. the \"yak\" strings will not overlap. \n",
      "  - Real Arguments :  ['string, ']\n",
      "  - Predicted Arguments :  ['string \"yak\" ', 'string, ', '\"yak\" strings ']\n",
      "\n",
      "<< Test number 24 >> \n",
      " [ Sentence ]  given a string of odd length, return the string length 3 from its middle, so \"candy\" yields \"and\". the string length will be at least 3. \n",
      "  - Real Arguments :  ['string of odd length, ', 'string ']\n",
      "  - Predicted Arguments :  ['string of odd length, ', 'string ', 'string ']\n",
      "\n",
      "<< Test number 25 >> \n",
      " [ Sentence ]  return true if the array contains, somewhere, three increasing adjacent numbers like .... 4, 5, 6, ... or 23, 24, 25. \n",
      "  - Real Arguments :  ['array ']\n",
      "  - Predicted Arguments :  ['array ']\n",
      "\n",
      "<< Test number 26 >> \n",
      " [ Sentence ]  start with two arrays of strings, a and b, each in alphabetical order, possibly with duplicates. return the count of the number of strings which appear in both arrays. the best \"linear\" solution makes a single pass over both arrays, taking advantage of the fact that they are in alphabetical order. \n",
      "  - Real Arguments :  ['two arrays of strings, ', 'a ', 'b, ', 'both arrays. ', 'both arrays, ']\n",
      "  - Predicted Arguments :  ['two arrays of strings, ', 'a ', 'b, ']\n",
      "\n",
      "<< Test number 27 >> \n",
      " [ Sentence ]  we have an array of heights, representing the altitude along a walking trail. given start/end indexes into the array, return the sum of the changes for a walk beginning at the start index and ending at the end index. for example, with the heights {5, 3, 6, 7, 2} and start end yields a sum of 1 + 5  6. the start end end index will both be valid indexes into the array with start < end. \n",
      "  - Real Arguments :  ['array of heights, ', 'start/end indexes ', 'array, ', 'start index ', 'end index. ', 'start ', 'end index ', 'indexes ', 'array ']\n",
      "  - Predicted Arguments :  ['array of heights, ', 'start/end indexes ', 'array, ', 'start index ', 'start ', 'end index ', 'array ']\n",
      "\n",
      "<< Test number 28 >> \n",
      " [ Sentence ]  given an array length 1 or more of ints, return the difference between the largest and smallest values in the array. note: the built-in math.min(v1, v2) and math.max(v1, v2) methods return the smaller or larger of two values. \n",
      "  - Real Arguments :  ['array ', 'array. ']\n",
      "  - Predicted Arguments :  ['ints, ', 'array. ']\n",
      "\n",
      "<< Test number 29 >> \n",
      " [ Sentence ]  given an array of non-empty strings, create and return a map<string, string> as follows: for each string add its first character as a key with its last character as the value. \n",
      "  - Real Arguments :  ['array of non-empty strings, ']\n",
      "  - Predicted Arguments :  ['array of non-empty strings, ']\n",
      "\n",
      "<< Test number 30 >> \n",
      " [ Sentence ]  this is slightly more difficult version of the famous fizzbuzz problem which is sometimes given as a first problem for job interviews. (see also: fizzbuzz code.) consider the series of numbers beginning at start and running up to but not including end, so for example start and end gives the series 1, 2, 3, 4. return a new string[] array containing the string form of these numbers, except for multiples of 3, use \"fizz\" instead of the number, for multiples of 5 use \"buzz\", and for multiples of both 3 and 5 use \"fizzbuzz\". in java, string.valueof(xxx) will make the string form of an int or other type. this version is a little more complicated than the usual version since you have to allocate and index into an array instead of just printing, and we vary the start/end instead of just always doing 1..100. \n",
      "  - Real Arguments :  ['start ', 'end, ']\n",
      "  - Predicted Arguments :  ['string ', 'numbers, ']\n",
      "\n",
      "<< Test number 31 >> \n",
      " [ Sentence ]  given a string that contains a single pair of parenthesis, compute recursively a new string made of only of the parenthesis and their contents, so \"xyz(abc)123\" yields \"(abc)\". \n",
      "  - Real Arguments :  ['string ']\n",
      "  - Predicted Arguments :  []\n",
      "\n",
      "<< Test number 32 >> \n",
      " [ Sentence ]  modify and return the given map as follows: if the key \"a\" has a value, set the key \"b\" to have that value, and set the key \"a\" to have the value \"\". basically \"b\" is a bully, taking the value and replacing it with the empty string. \n",
      "  - Real Arguments :  ['map ']\n",
      "  - Predicted Arguments :  ['map ']\n",
      "\n",
      "<< Test number 33 >> \n",
      " [ Sentence ]  start with two arrays of strings, a and b, each with its elements in alphabetical order and without duplicates. return a new array containing the first n elements from the two arrays. the result array should be in alphabetical order and without duplicates. a and b will both have a length which is n or more. the best \"linear\" solution makes a single pass over a and b, taking advantage of the fact that they are in alphabetical order, copying elements directly to the new array. \n",
      "  - Real Arguments :  ['two arrays of strings, ', 'a ', 'b, ', 'n ', 'two arrays. ', 'a ', 'b ', 'n ', 'a ', 'b, ']\n",
      "  - Predicted Arguments :  ['two arrays of strings, ', 'a ', 'n ', 'two arrays. ', 'b ', 'n ']\n",
      "\n",
      "<< Test number 34 >> \n",
      " [ Sentence ]  given an int n, return the string form of the number followed by \"!\". so the int 6 yields \"6!\". except if the number is divisible by 3 use \"fizz\" instead of the number, and if the number is divisible by 5 use \"buzz\", and if divisible by both 3 and 5, use \"fizzbuzz\". note: the % \"mod\" operator computes the remainder after division, so 23 % 10 yields 3. what will the remainder be when one number divides evenly into another? (see also: fizzbuzz code and introduction to mod) \n",
      "  - Real Arguments :  ['int n, ', 'number ', 'number ', 'number, ', 'number ']\n",
      "  - Predicted Arguments :  ['int n, ', 'string ']\n",
      "\n",
      "<< Test number 35 >> \n",
      " [ Sentence ]  given two strings, a and b, create a bigger string made of the first char of a, the first char of b, the second char of a, the second char of b, and so on. any leftover chars go at the end of the result. \n",
      "  - Real Arguments :  ['two strings, ', 'a ', 'b, ', 'bigger string ', 'a, ', 'b, ', 'a, ', 'b, ']\n",
      "  - Predicted Arguments :  ['two strings, ', 'a ', 'b, ', 'b, ']\n",
      "\n",
      "<< Test number 36 >> \n",
      " [ Sentence ]  given a list of strings, return a list of the strings, omitting any string length 4 or more. \n",
      "  - Real Arguments :  ['list of strings, ']\n",
      "  - Predicted Arguments :  ['list of strings, ']\n",
      "\n",
      "<< Test number 37 >> \n",
      " [ Sentence ]  given a string, return a \"rotated right 2\" version where the last 2 chars are moved to the start. the string length will be at least 2. \n",
      "  - Real Arguments :  ['string, ', 'string ']\n",
      "  - Predicted Arguments :  ['string, ', 'string ']\n",
      "\n",
      "<< Test number 38 >> \n",
      " [ Sentence ]  given 2 int arrays, a and b, of any length, return a new array with the first element of each array. if either array is length 0, ignore that array. \n",
      "  - Real Arguments :  ['2 int arrays, ', 'a ', 'b, ', 'array. ', 'array ']\n",
      "  - Predicted Arguments :  ['2 int arrays, ', 'a ', 'b, ']\n",
      "\n",
      "<< Test number 39 >> \n",
      " [ Sentence ]  return an array that contains the exact same numbers as the given array, but rearranged so that all the zeros are grouped at the start of the array. the order of the non-zero numbers does not matter. so {1, 0, 0, 1} becomes {0 ,0, 1, 1}. you may modify and return the given array or make a new array. \n",
      "  - Real Arguments :  ['array, ', 'array ']\n",
      "  - Predicted Arguments :  ['array, ', 'array. ', 'array ']\n",
      "\n",
      "<< Test number 40 >> \n",
      " [ Sentence ]  given a string, we'll say that the front is the first 3 chars of the string. if the string length is less than 3, the front is whatever is there. return a new string which is 3 copies of the front. \n",
      "  - Real Arguments :  ['string, ', 'string. ', 'string ']\n",
      "  - Predicted Arguments :  ['string, ', 'string. ', 'string ']\n",
      "\n",
      "<< Test number 41 >> \n",
      " [ Sentence ]  given an array of ints, return true if the array contains a 2 next to a 2 or a 4 next to a 4, but not both. \n",
      "  - Real Arguments :  ['array of ints, ', 'array ']\n",
      "  - Predicted Arguments :  ['array of ints, ', 'array ']\n",
      "\n",
      "<< Test number 42 >> \n",
      " [ Sentence ]  given a non-negative int n, return the count of the occurrences of 7 as a digit, so for example 717 yields 2. (no loops). note that mod (%) by 10 yields the rightmost digit (126 % 10 is 6), while divide (/) by 10 removes the rightmost digit (126 / 10 is 12). \n",
      "  - Real Arguments :  ['non-negative int n, ']\n",
      "  - Predicted Arguments :  ['non-negative int n, ']\n",
      "\n",
      "<< Test number 43 >> \n",
      " [ Sentence ]  you have a blue lottery ticket, with ints a, b, and c on it. this makes three pairs, which we'll call ab, bc, and ac. consider the sum of the numbers in each pair. if any pair sums to exactly 10, the result is 10. otherwise if the ab sum is exactly 10 more than either bc or ac sums, the result is 5. otherwise the result is 0. \n",
      "  - Real Arguments :  ['ints ', 'a, ', 'b, ', 'c ', 'numbers ']\n",
      "  - Predicted Arguments :  []\n",
      "\n",
      "<< Test number 44 >> \n",
      " [ Sentence ]  given an array of ints, return a new array length 2 containing the first and last elements from the original array. the original array will be length 1 or more. \n",
      "  - Real Arguments :  ['array of ints, ', 'original array. ', 'original array ']\n",
      "  - Predicted Arguments :  ['array of ints, ', 'original array. ', 'original array ']\n",
      "\n",
      "<< Test number 45 >> \n",
      " [ Sentence ]  given a string and an int n, return a string made of the first n characters of the string, followed by the first n-1 characters of the string, and so on. you may assume that n is between 0 and the length of the string, inclusive (i.e. n > 0 and n < str.length()). \n",
      "  - Real Arguments :  ['string ', 'int n, ', 'n ', 'string, ', 'string, ', 'n ', 'string, ']\n",
      "  - Predicted Arguments :  ['string ', 'int n, ', 'string, ', 'string, ', 'n ', 'string, inclusive ', 'n ']\n",
      "\n",
      "<< Test number 46 >> \n",
      " [ Sentence ]  given a list of non-negative integers, return a list of those numbers except omitting any that end with 9. (note: % by 10) \n",
      "  - Real Arguments :  ['list of non-negative integers, ']\n",
      "  - Predicted Arguments :  ['list of non-negative integers, ']\n",
      "\n",
      "<< Test number 47 >> \n",
      " [ Sentence ]  given a string and a non-empty word string, return a version of the original string where all chars have been replaced by pluses (\"+\"), except for appearances of the word string which are preserved unchanged. \n",
      "  - Real Arguments :  ['string ', 'non-empty word string, ', 'original ', 'string ', 'word string ']\n",
      "  - Predicted Arguments :  ['string ', 'non-empty word string, ', 'word ']\n",
      "\n",
      "<< Test number 48 >> \n",
      " [ Sentence ]  given a string, return true if \"bad\" appears starting at index 0 or 1 in the string, such as with \"badxxx\" or \"xbadxx\" but not \"xxbadxx\". the string may be any length, including 0. note: use .equals() to compare 2 strings. \n",
      "  - Real Arguments :  ['string, ', 'string, ', 'string ']\n",
      "  - Predicted Arguments :  ['string, ', 'string, ', 'string ']\n",
      "\n",
      "<< Test number 49 >> \n",
      " [ Sentence ]  given a string, return a version where all the \"x\" have been removed. except an \"x\" at the very start or end should not be removed. \n",
      "  - Real Arguments :  ['string, ']\n",
      "  - Predicted Arguments :  ['string, ']\n",
      "\n",
      "<< Test number 50 >> \n",
      " [ Sentence ]  given 2 strings, a and b, return the number of the positions where they contain the same length 2 substring. so \"xxcaazz\" and \"xxbaaz\" yields 3, since the \"xx\", \"aa\", and \"az\" substrings appear in the same place in both strings. \n",
      "  - Real Arguments :  ['2 strings, ', 'a ', 'b, ']\n",
      "  - Predicted Arguments :  ['2 strings, ', 'a ', 'b, ']\n",
      "\n",
      "<< Test number 51 >> \n",
      " [ Sentence ]  for this problem, we'll round an int value up to the next multiple of 10 if its rightmost digit is 5 or more, so 15 rounds up to 20. alternately, round down to the previous multiple of 10 if its rightmost digit is less than 5, so 12 rounds down to 10. given 3 ints, a b c, return the sum of their rounded values. to avoid code repetition, write a separate helper \"public int round10(int num) {\" and call it 3 times. write the helper entirely below and at the same indent level as roundsum(). \n",
      "  - Real Arguments :  ['3 ints, ', 'a ', 'b ', 'c, ']\n",
      "  - Predicted Arguments :  ['3 ints, ', 'a ', 'b ', 'c, ']\n",
      "\n",
      "<< Test number 52 >> \n",
      " [ Sentence ]  you have a red lottery ticket showing ints a, b, and c, each of which is 0, 1, or 2. if they are all the value 2, the result is 10. otherwise if they are all the same, the result is 5. otherwise so long as both b and c are different from a, the result is 1. otherwise the result is 0. \n",
      "  - Real Arguments :  ['ints ', 'a, ', 'b, ', 'c, ', 'b ', 'c ', 'a, ']\n",
      "  - Predicted Arguments :  ['c, ', 'c ']\n",
      "\n",
      "<< Test number 53 >> \n",
      " [ Sentence ]  return true if the given string contains between 1 and 3 'e' chars. \n",
      "  - Real Arguments :  ['string ']\n",
      "  - Predicted Arguments :  ['string ']\n",
      "\n",
      "<< Test number 54 >> \n",
      " [ Sentence ]  given a string, return a string where every appearance of the lowercase word \"is\" has been replaced with \"is not\". the word \"is\" should not be immediately preceeded or followed by a letter -- so for example the \"is\" in \"this\" does not count. (note: character.isletter(char) tests if a char is a letter.) \n",
      "  - Real Arguments :  ['string, ']\n",
      "  - Predicted Arguments :  ['string, ']\n",
      "\n",
      "<< Test number 55 >> \n",
      " [ Sentence ]  we'll say that a value is \"everywhere\" in an array if for every pair of adjacent elements in the array, at least one of the pair is that value. return true if the given value is everywhere in the array. \n",
      "  - Real Arguments :  ['array ', 'array, ', 'value ']\n",
      "  - Predicted Arguments :  ['array, ', 'value ']\n",
      "\n",
      "<< Test number 56 >> \n",
      " [ Sentence ]  given a non-empty array of ints, return a new array containing the elements from the original array that come before the first 4 in the original array. the original array will contain at least one 4. note that it is valid in java to create an array of length 0. \n",
      "  - Real Arguments :  ['array of ints, ', 'original array ', 'original array. ', 'original array ']\n",
      "  - Predicted Arguments :  ['array of ints, ', 'original array ', 'original array. ', 'original array ']\n",
      "\n",
      "<< Test number 57 >> \n",
      " [ Sentence ]  given a string, return a \"rotated left 2\" version where the first 2 chars are moved to the end. the string length will be at least 2. \n",
      "  - Real Arguments :  ['string, ', 'string ']\n",
      "  - Predicted Arguments :  ['string, ', 'string ']\n",
      "\n",
      "<< Test number 58 >> \n",
      " [ Sentence ]  given a string, if a length 2 substring appears at both its beginning and end, return a string without the substring at the beginning, so \"hellohe\" yields \"llohe\". the substring may overlap with itself, so \"hi\" yields \"\". otherwise, return the original string unchanged. \n",
      "  - Real Arguments :  ['string, ', 'original string ']\n",
      "  - Predicted Arguments :  ['string, ', 'end, ', 'string ', 'beginning, ', 'string ']\n",
      "\n",
      "<< Test number 59 >> \n",
      " [ Sentence ]  given an array of ints, return true if it contains a 2, 7, 1 pattern: a value, followed by the value plus 5, followed by the value minus 1. additionally the 271 counts even if the \"1\" differs by 2 or less from the correct value. \n",
      "  - Real Arguments :  ['array of ints, ']\n",
      "  - Predicted Arguments :  ['array of ints, ']\n",
      "\n",
      "<< Test number 60 >> \n",
      " [ Sentence ]  return true if the given non-negative number is a multiple of 3 or 5, but not both. use the % \"mod\" operator -- see introduction to mod \n",
      "  - Real Arguments :  ['non-negative number ']\n",
      "  - Predicted Arguments :  ['non-negative number ']\n",
      "\n",
      "<< Test number 61 >> \n",
      " [ Sentence ]  given a string, return true if the first 2 chars in the string also appear at the end of the string, such as with \"edited\". \n",
      "  - Real Arguments :  ['string, ', 'string ', 'string, ']\n",
      "  - Predicted Arguments :  ['string, ', 'string ', 'string, ']\n"
     ]
    }
   ],
   "source": [
    "for num in range(0, num_of_testset):\n",
    "    sentence = ''\n",
    "    \n",
    "    p_temp_arg = ''; p_prev_label = 'X'\n",
    "    r_temp_arg = ''; r_prev_label = 'X'\n",
    "    \n",
    "    p_args = []; r_args = []\n",
    "    \n",
    "    print(\"\\n<< Test number %s >> \" %(num))\n",
    "    \n",
    "    for i in range(len(y_pred[num])):\n",
    "        word  =  X_test[num][i][1].split(\"=\")[1]\n",
    "        p_label = y_pred[num][i]\n",
    "        r_label = y_test[num][i]\n",
    "\n",
    "        # ========== real arguements ==================\n",
    "        if r_label == 'X':\n",
    "            if r_prev_label != 'X': # [P -> X]\n",
    "                r_args.append(r_temp_arg)\n",
    "                r_temp_arg = '' \n",
    "            else: pass # [X -> X]\n",
    "        else:\n",
    "            if r_prev_label == 'X': # [X -> P]\n",
    "                r_temp_arg += (word + ' ')\n",
    "            else:\n",
    "                if (r_prev_label[0] == 'B' or r_prev_label[0] == 'I') and r_label[0] == 'I' :  # [P -> same P]\n",
    "                    r_temp_arg += (word + ' ')\n",
    "                else: # [P -> different P]\n",
    "                    r_args.append(r_temp_arg) \n",
    "                    r_temp_arg = (word + ' ') \n",
    "        r_prev_label = r_label\n",
    "        # ===========================================\n",
    "    \n",
    "        # =========predicted arguments =================\n",
    "        if p_label == 'X':\n",
    "            if p_prev_label != 'X':  \n",
    "                p_args.append(p_temp_arg)\n",
    "                p_temp_arg = '' \n",
    "            else: pass \n",
    "        else:\n",
    "            if p_prev_label == 'X': \n",
    "                p_temp_arg += (word + ' ')\n",
    "            else:\n",
    "                if (p_prev_label[0] == 'B' or p_prev_label[0] == 'I') and p_label[0] == 'I' : \n",
    "                    p_temp_arg += (word + ' ')\n",
    "                else: \n",
    "                    p_args.append(p_temp_arg) \n",
    "                    p_temp_arg = (word + ' ') \n",
    "        p_prev_label = p_label\n",
    "        # ===========================================\n",
    "        sentence += (word + ' ')\n",
    "    print(\" [ Sentence ] \", sentence)\n",
    "    print(\"  - Real Arguments : \", r_args)\n",
    "    print(\"  - Predicted Arguments : \", p_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. precision & recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           X       0.98      0.99      0.98      1899\n",
      "     B-param       0.81      0.89      0.85        83\n",
      "     I-param       0.78      0.90      0.83        39\n",
      "    B-nparam       0.87      0.74      0.80        70\n",
      "    I-nparam       0.93      0.76      0.84        51\n",
      "    B-param2       0.64      0.33      0.44        21\n",
      "    I-param2       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.96      2170\n",
      "   macro avg       0.71      0.66      0.68      2170\n",
      "weighted avg       0.96      0.96      0.96      2170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create a mapping of labels to indices\n",
    "labels = {\"X\": 0, \"B-param\": 1, \"I-param\" : 2, \"B-nparam\" : 3, \"I-nparam\" : 4, \"B-param2\" : 5, \"I-param2\" : 6, \"B-param3\" : 7, \"I-param3\" : 8\n",
    "         }\n",
    "\n",
    "# Convert the sequences of tags into a 1-dimensional array\n",
    "predictions = np.array([labels[tag] for row in y_pred for tag in row])\n",
    "truths = np.array([labels[tag] for row in y_test for tag in row])\n",
    "\n",
    "# Print out the classification report\n",
    "print(classification_report(\n",
    "    truths, predictions,\n",
    "    target_names=[\"X\", \"B-param\", \"I-param\", \"B-nparam\", \"I-nparam\",\n",
    "                  \"B-param2\", \"I-param2\"#, \"B-param3\", \"I-param3\"\n",
    "                 ])\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
